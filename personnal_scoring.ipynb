{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.metrics import mean_squared_error, ndcg_score, dcg_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import NMF\n",
    "from select_data import select#, intersection\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('matrice_avis_utilisateur.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             movie       rating\n",
      "count  3706.000000  3706.000000\n",
      "mean   1995.573125   269.889099\n",
      "std    1151.148045   384.047838\n",
      "min       1.000000     1.000000\n",
      "25%     989.250000    33.000000\n",
      "50%    2033.500000   123.500000\n",
      "75%    2990.750000   350.000000\n",
      "max    3952.000000  3428.000000\n",
      "            rating         user\n",
      "count  6040.000000  6040.000000\n",
      "mean    130.904305  3020.500000\n",
      "std     136.600298  1743.742145\n",
      "min       7.000000     1.000000\n",
      "25%      37.000000  1510.750000\n",
      "50%      80.000000  3020.500000\n",
      "75%     171.000000  4530.250000\n",
      "max     980.000000  6040.000000\n"
     ]
    }
   ],
   "source": [
    "from select_data import select\n",
    "\n",
    "data=select(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selection des users qui ont un std large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43654, 34923, 8731)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split des data\n",
    "X_train, X_test = train_test_split(data, train_size=0.8, random_state=42, shuffle=True)\n",
    "len(data),len(X_train),len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8731"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conservation des films qui ont eté vue a l'entrainement\n",
    "X_test=X_test[X_test['movie'].isin(X_train['movie'].unique())]\n",
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8731"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conservation des users qui ont eté vue a l'entrainement\n",
    "X_test=X_test[X_test['user'].isin(X_train['user'].unique())]\n",
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sparse = X_train.astype(pd.SparseDtype(\"float\", 0))\n",
    "test_sparse = X_test.astype(pd.SparseDtype(\"float\", 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain=train_sparse.pivot(columns='movie',index='user',values='rating').fillna(0)\n",
    "dtest=test_sparse.pivot(columns='movie',index='user',values='rating').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with mlflow.start_run() as run:\n",
    "#     mlflow.sklearn.log_model(NMFRecommender, \"NMFRecommender\", registered_model_name=\"NMFRecommenderModel\")\n",
    "#     mlflow.log_params({\"n_components\": n_components, \"max_iter\": max_iter})\n",
    "#     mlflow.log_metric(\"Training MSE\", mse_train)\n",
    "#     mlflow.log_metric(\"Test MSE\", mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/02/16 15:03:12 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "2024/02/16 15:03:13 WARNING mlflow.sklearn: Training metrics will not be recorded because training labels were not specified. To automatically record training metrics, provide training labels as inputs to the model training function.\n",
      "2024/02/16 15:03:13 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2024/02/16 15:03:18 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\Utilisateur\\anaconda3\\Lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\"\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "n_components=18\n",
    "max_iter=2000\n",
    "\n",
    "mlflow.autolog()\n",
    "\n",
    "with mlflow.start_run():\n",
    "    # mlflow.sklearn.log_model(NMFRecommender, \"NMFRecommender\", registered_model_name=\"NMFRecommenderModel\")\n",
    "    mlflow.log_params({\"n_components\": n_components, \"max_iter\": max_iter})\n",
    "\n",
    "    nmf = NMF(n_components=n_components,max_iter=max_iter)\n",
    "    \n",
    "    \n",
    "   # Fit the model to the user-item matrix\n",
    "    W = nmf.fit_transform(dtrain.values)  # User matrix\n",
    "    H = nmf.components_  # Item matrix\n",
    "\n",
    "    # nmf_result_test = nmf.transform(dtest.values)\n",
    "\n",
    "    pred_matrix = np.dot(W,H)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/02/16 15:03:18 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'a509ffe5167441e3bdd28085e8d0cf50', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n",
      "2024/02/16 15:03:23 WARNING mlflow.sklearn: Training metrics will not be recorded because training labels were not specified. To automatically record training metrics, provide training labels as inputs to the model training function.\n",
      "2024/02/16 15:03:23 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n"
     ]
    }
   ],
   "source": [
    "nmf = NMF(n_components=100,max_iter=10000)\n",
    "# Fit the model to the user-item matrix\n",
    "W = nmf.fit_transform(dtrain.values)  # User matrix\n",
    "H = nmf.components_  # Item matrix\n",
    "pred_matrix = np.dot(W,H) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring=pd.DataFrame(pred_matrix)\n",
    "scoring.columns=dtrain.columns\n",
    "scoring.index=dtrain.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# scoring.T\n",
    "# scaler=MinMaxScaler()\n",
    "# scaler.fit([[1,5],[1,5]])\n",
    "# scaler.transform(scoring)\n",
    "# print(scaler.data_max_)\n",
    "# scoring=scaler.transform(scoring)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "unpivot_scoring=scoring.reset_index().melt(id_vars='user', var_name='movie', value_name='scoring')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "unpivot_scoring['user']=unpivot_scoring['user'].sparse.to_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred_df = pd.merge(X_train, unpivot_scoring, on=['user', 'movie'])\n",
    "test_pred_df = pd.merge(X_test, unpivot_scoring, on=['user', 'movie'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8407900892099804\n",
      "12.65466309650533\n"
     ]
    }
   ],
   "source": [
    "print(mean_squared_error(train_pred_df['rating'],train_pred_df['scoring']))\n",
    "print(mean_squared_error(test_pred_df['rating'],test_pred_df['scoring']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie</th>\n",
       "      <th>user</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>858</td>\n",
       "      <td>6040</td>\n",
       "      <td>956703932</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2384</td>\n",
       "      <td>6040</td>\n",
       "      <td>956703954</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>593</td>\n",
       "      <td>6040</td>\n",
       "      <td>956703954</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>6040</td>\n",
       "      <td>956703977</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1961</td>\n",
       "      <td>6040</td>\n",
       "      <td>956703977</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000204</th>\n",
       "      <td>2399</td>\n",
       "      <td>4958</td>\n",
       "      <td>1046454338</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000205</th>\n",
       "      <td>1407</td>\n",
       "      <td>4958</td>\n",
       "      <td>1046454443</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000206</th>\n",
       "      <td>3264</td>\n",
       "      <td>4958</td>\n",
       "      <td>1046454548</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000207</th>\n",
       "      <td>2634</td>\n",
       "      <td>4958</td>\n",
       "      <td>1046454548</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000208</th>\n",
       "      <td>1924</td>\n",
       "      <td>4958</td>\n",
       "      <td>1046454590</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000209 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         movie  user   timestamp  rating\n",
       "0          858  6040   956703932       4\n",
       "1         2384  6040   956703954       4\n",
       "2          593  6040   956703954       5\n",
       "3         2019  6040   956703977       5\n",
       "4         1961  6040   956703977       4\n",
       "...        ...   ...         ...     ...\n",
       "1000204   2399  4958  1046454338       1\n",
       "1000205   1407  4958  1046454443       5\n",
       "1000206   3264  4958  1046454548       4\n",
       "1000207   2634  4958  1046454548       3\n",
       "1000208   1924  4958  1046454590       4\n",
       "\n",
       "[1000209 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intersection proportion\n",
    "\n",
    "def intersection(value):\n",
    "    total=0\n",
    "    total_user_section_size=0\n",
    "    list_accuracy=[]\n",
    "\n",
    "    for indice,user in enumerate(train_pred_df['user'].unique()):\n",
    "\n",
    "        # if indice>0 :\n",
    "        #     break\n",
    "        \n",
    "        user_section=test_pred_df[test_pred_df['user']==user]\n",
    "        user_section_size=len(user_section)\n",
    "        size_top=value/100\n",
    "        limit=round(user_section_size*size_top)\n",
    "        total_user_section_size+=user_section_size\n",
    "\n",
    "\n",
    "        user_pref=user_section.sort_values('rating',ascending=False)['movie'][:limit]\n",
    "        # print(len(user_pref))\n",
    "        # print((user_pref))\n",
    "        user_recommandation=user_section.sort_values('scoring',ascending=False)['movie'][:limit]\n",
    "        # (len(user_recommandation))\n",
    "        # print((user_recommandation))\n",
    "        valid_recommandation=user_recommandation[user_recommandation.isin(user_pref)]\n",
    "\n",
    "        how_many_valid_recomandation=len(valid_recommandation)\n",
    "        try : \n",
    "            accuracy=(how_many_valid_recomandation/user_section_size)*100\n",
    "        except : \n",
    "            accuracy=0\n",
    "\n",
    "\n",
    "        list_accuracy+=[accuracy]\n",
    "\n",
    "        total+=how_many_valid_recomandation\n",
    "\n",
    "    mean_intersection=round(total/len(train_pred_df['user'].unique()))\n",
    "    mean_user_section_size=round(total_user_section_size/len(train_pred_df['user'].unique()))\n",
    "    mean_accuracy=(mean_intersection/mean_user_section_size)*100\n",
    "\n",
    "    std=(1/2)**sum([ (x-mean_accuracy)**2 for x in list_accuracy])\n",
    "    # print(mean_intersection,mean_user_section_size)\n",
    "    return mean_accuracy,std\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 % accuracy 0.0 0.0\n",
      "20 % accuracy 3.8461538461538463 0.0\n",
      "30 % accuracy 11.538461538461538 0.0\n",
      "40 % accuracy 19.230769230769234 0.0\n",
      "50 % accuracy 26.923076923076923 0.0\n",
      "60 % accuracy 38.46153846153847 0.0\n",
      "70 % accuracy 50.0 0.0\n",
      "80 % accuracy 65.38461538461539 0.0\n",
      "90 % accuracy 80.76923076923077 0.0\n",
      "100 % accuracy 100.0 1.0\n"
     ]
    }
   ],
   "source": [
    "for x in range(10,101,10):\n",
    "    mean,std=intersection(x)\n",
    "    print(x,'%','accuracy',mean,std,sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "19.230769230769234\n",
      "38.46153846153847\n",
      "48.07692307692308\n",
      "53.84615384615385\n",
      "64.1025641025641\n",
      "71.42857142857143\n",
      "81.73076923076923\n",
      "89.74358974358975\n",
      "100.0\n"
     ]
    }
   ],
   "source": [
    "for x in range(10,101,10):\n",
    "    mean,std=intersection(x)\n",
    "    print((mean/x)*100)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.log_metric(\"Training MSE\",mean_squared_error(train_pred_df['rating'],train_pred_df['scoring']))\n",
    "                      \n",
    "mlflow.log_metric(\"Test MSE\",mean_squared_error(test_pred_df['rating'],test_pred_df['scoring']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9932303500859223\n",
      "0.9748281215705205\n"
     ]
    }
   ],
   "source": [
    "print(ndcg_score([train_pred_df['rating'].values], [train_pred_df['scoring'].values]))\n",
    "print(ndcg_score([test_pred_df['rating'].values], [test_pred_df['scoring'].values]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9847.17960759842\n",
      "356.9799176416209\n"
     ]
    }
   ],
   "source": [
    "print(dcg_score([train_pred_df['rating'].values], [train_pred_df['scoring'].values]))\n",
    "print(dcg_score([test_pred_df['scoring'].values], [test_pred_df['scoring'].values]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3144673885.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[26], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    train_data, test_data, train_mini, test_mini=partition(df, test_size=0.2, mini_size=0.03):\u001b[0m\n\u001b[1;37m                                                                                             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def run (file): \n",
    "    df = pd.read_csv(csv_path)\n",
    "    train_data, test_data, train_mini, test_mini=partition(df, test_size=0.2, mini_size=0.03):\n",
    "    MF_training(n_components, max_iter, df):\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
